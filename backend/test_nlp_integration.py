#!/usr/bin/env python3
"""
Test script for NLP processor integration with PromptManager
"""

import sys
import asyncio
from pathlib import Path

# Add the current directory to Python path
sys.path.append('.')

from chatbot.ollama_nlp_processor import OllamaMedicalNLPProcessor
from chatbot.prompt_manager import PromptManager

async def test_nlp_integration():
    """Test the NLP processor integration with PromptManager"""
    
    print("ğŸ§ª Testing NLP Integration with PromptManager...")
    
    try:
        # Initialize PromptManager
        pm = PromptManager()
        print(f"âœ… PromptManager initialized")
        
        # Initialize Ollama NLP processor
        nlp = OllamaMedicalNLPProcessor()
        print(f"âœ… Ollama NLP processor initialized")
        
        # Test queries for different intents
        test_queries = [
            ("What is the patient past medical history?", "pmh_query"),
            ("What conditions does this patient have?", "condition_query"),
            ("What allergies does this patient have?", "allergy_query"),
            ("What medications is the patient taking?", "medication_query"),
        ]
        
        print(f"\nğŸ” Testing intent classification with PromptManager...")
        
        for query, expected_intent in test_queries:
            print(f"\nğŸ“ Testing query: '{query}'")
            print(f"   Expected intent: {expected_intent}")
            
            # Test intent classification
            try:
                intent = await nlp.classify_intent(query)
                print(f"   âœ… Classified intent: {intent}")
                
                if intent == expected_intent:
                    print(f"   ğŸ¯ CORRECT classification!")
                else:
                    print(f"   âŒ INCORRECT classification (expected: {expected_intent})")
                
                # Test prompt retrieval
                prompt = pm.get_intent_prompt(intent)
                if prompt:
                    print(f"   ğŸ“‹ Retrieved prompt for {intent}")
                    print(f"      System prompt: {len(prompt['system_prompt'])} chars")
                    print(f"      User prompt: {len(prompt['user_prompt'])} chars")
                else:
                    print(f"   âš ï¸  No prompt found for intent: {intent}")
                    
            except Exception as e:
                print(f"   âŒ Error testing query: {e}")
        
        # Test PromptManager functionality
        print(f"\nğŸ“Š PromptManager Statistics:")
        stats = pm.get_prompt_statistics()
        print(f"   Total intents: {stats['total_intents']}")
        print(f"   Active intents: {stats['active_intents']}")
        print(f"   Average prompt length: {stats['avg_prompt_length']} chars")
        
        # Test validation
        print(f"\nğŸ” Configuration Validation:")
        validation_results = pm.validate_configurations()
        for intent, errors in validation_results.items():
            if errors:
                print(f"   âŒ {intent}: {len(errors)} errors")
            else:
                print(f"   âœ… {intent}: Valid")
        
        print(f"\nğŸ‰ NLP Integration test completed!")
        
    except Exception as e:
        print(f"âŒ Test failed with error: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    return True

if __name__ == "__main__":
    success = asyncio.run(test_nlp_integration())
    sys.exit(0 if success else 1)
